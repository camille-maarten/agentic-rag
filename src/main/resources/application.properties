quarkus.langchain4j.timeout=60s
quarkus.http.port=8080

# local podman hosted llm.
%dev.quarkus.langchain4j.openai.base-url=http://localhost:52819/v1
# Required for ingestion of documents
%dev.documents.dir=${INGEST_DOCUMENTS_DIR}

# give it some more time, based on local resources..
%dev.quarkus.langchain4j.openai.timeout=180s
# Enable logging of both requests and responses
%dev.quarkus.langchain4j.openai.log-requests=true
%dev.quarkus.langchain4j.openai.log-responses=true


# Elastic search local dev
# the docker-compose file has ml enabled.
%dev.quarkus.elasticsearch.hosts=localhost:9200
%dev.quarkus.elasticsearch.username=elastic
%dev.quarkus.elasticsearch.password=changeme
quarkus.elasticsearch.devservices.enabled=false


# S3 storage backend by minio. current sandbox setup.
minio.endpoint=https://play.min.io
minio.access-key=${MINIO_ACCESS_KEY}
minio.secret-key=${MINIO_SECRET_KEY}
minio.bucket-name="jakarata12-bucket"


# Production profile, in this case on OpenShift

%prod.quarkus.openshift.pvc-volumes.ai-documents.claim-name=ai-documents
%prod.quarkus.openshift.mounts.ai-documents.path=/deployments/documents
%prod.quarkus.openshift.route.expose=true
%prod.quarkus.kubernetes-client.trust-certs=true

##%prod.quarkus.openshift.pvc-volumes.ai-documents.mount-path=/deployments/documents
%prod.quarkus.elasticsearch.hosts=elasticsearch-sample-es-internal-http.elastic-vectordb.svc.cluster.local:9200
%prod.quarkus.elasticsearch.username=elastic
%prod.quarkus.elasticsearch.password=changeme
#%prod.quarkus.elasticsearch.ssl=true
#%prod.quarkus.elasticsearch.truststore=/deployments/config/elasticsearch-truststore.jks
#%prod.quarkus.elasticsearch.truststore-password=changeit
%prod.quarkus.elasticsearch.protocol=https
%prod.documents.dir=/deployments/documents
%prod.quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}


